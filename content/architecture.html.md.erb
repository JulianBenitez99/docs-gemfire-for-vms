---
title: Pivotal Cloud Cache Architecture
---

<!-- 
Copyright (c) VMware, Inc. 2022. All rights reserved.
Licensed to the Apache Software Foundation (ASF) under one or more contributor license
agreements. See the NOTICE file distributed with this work for additional information regarding
copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance with the License. You may obtain a
copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License
is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
or implied. See the License for the specific language governing permissions and limitations under
the License.
-->

## <a id='GFBasics'></a>Pivotal GemFire&reg; Basics

Pivotal GemFire is the data store within Pivotal Cloud Cache (PCC). A PCC service instance requires a small amount of administrative GemFire setup, and any app will use a limited portion of the GemFire API.

The PCC architectural model is a client-server model. The clients are apps or microservices, and the servers are a set of GemFire servers maintained by a PCC service instance. The GemFire servers provide a low-latency, consistent, fault-tolerant data store within PCC.

![Client Server Model](client-server.png)

GemFire holds data in key/value pairs. Each pair is called an **entry**. Entries are logically grouped into sets called **regions**. A region is a map (or dictionary) data structure.

The app (client) uses PCC as a cache. A cache lookup (read) is a get operation on a GemFire region. The cache operation of a cache write is a put operation on a GemFire region.
The GemFire command-line interface, called gfsh, facilitates region administration. Use gfsh to create and destroy regions within the PCC service instance.

## <a id='pcc-cluster-architecture'></a>The PCC Cluster

PCC deploys cache clusters that use Pivotal GemFire to provide high availability, replication guarantees, and eventual consistency.

When you first spin up a cluster, you have three locators and at least four servers.

<% mermaid_diagram do %>
  graph TD;
  Client
  subgraph P-CloudCache Cluster
  subgraph locators
  Locator1
  Locator2
  Locator3
  end
  subgraph servers
  Server1
  Server2
  Server3
  Server4
  end
  end
  Client==>Locator1
  Client-->Server1
  Client-->Server2
  Client-->Server3
  Client-->Server4
<% end %>

When you scale up the cluster, you have more servers, increasing the capacity of the cache. There are always three locators.

<% mermaid_diagram do %>
  graph TD;
  Client
  subgraph P-CloudCache Cluster
  subgraph locators
  Locator1
  Locator2
  Locator3
  end
  subgraph servers
  Server1
  Server2
  Server3
  Server4
  Server5
  Server6
  Server7
  end
  end
  Client==>Locator1
  Client-->Server1
  Client-->Server2
  Client-->Server3
  Client-->Server4
  Client-->Server5
  Client-->Server6
  Client-->Server7
<% end %>

## <a id='MemberCommunication'></a>Member Communication

When a client connects to the cluster, it first connects to a locator. The locator replies with the IP address of a server for it to talk to. The client then connects to that server.

<% mermaid_diagram do %>
  sequenceDiagram
    participant Client
    participant Locator
    participant Server1
    Client->>+Locator: What servers can I talk to?
    Locator->>-Client: Server1
    Client->>Server1: Hello!
<% end %>

When the client wants to read or write data, it sends a request directly to the server.

<% mermaid_diagram do %>
  sequenceDiagram
    participant Client
    participant Server1
    Client->>+Server1: What's the value for KEY?
    Server1->>-Client: VALUE
<% end %>

If the server doesn't have the data locally, it fetches it from another server.

<% mermaid_diagram do %>
  sequenceDiagram
    participant Client
    participant Server1
    participant Server2
    Client->>+Server1: What's the value for KEY?
    Server1->>+Server2: What's the value for KEY?
    Server2->>-Server1: VALUE
    Server1->>-Client: VALUE
<% end %>
