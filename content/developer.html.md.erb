---
title: Pivotal Cloud Cache Developer Guide
owner: Cloud Cache Engineers
---

In this topic:

- [Accessing a Service Instance](accessing-instance.html)
    - [Create Service Keys](accessing-instance.html#create-service-key)
    - [Connect with gfsh](accessing-instance.html#gfsh-connect)
    - [Connect with gfsh over HTTPS](accessing-instance.html#gfsh-connect-https)
        - [Create a Truststore](accessing-instance.html#truststore)
        - [Establish the Connection with HTTPS](accessing-instance.html#establish-https)
- [Using Pivotal Cloud Cache](using-pcc.html)
    - [Create Regions with gfsh](using-pcc.html#create-regions)
    - [Java Build Pack Requirements](using-pcc.html#java-build-pack-requirement)
    - [Bind an App to a Service Instance](using-pcc.html#bind-service)
    - [Use the Pulse Dashboard](using-pcc.html#pulse)
    - [Access Service Metrics](using-pcc.html#nozzle)
    - [Access Service Broker Metrics](using-pcc.html#nozzle-service-metrics)
    - [Export gfsh logs](using-pcc.html#exporting_logs)
- [Connecting a Spring Boot App to Pivotal Cloud Cache with Session State Caching](Spring-SessionState.html)
    - [Use the Tomcat App](Spring-SessionState.html#tomcat)
    - [Use a Spring Session Data GemFire App](Spring-SessionState.html#spring-session)
- [Creating Continuous Queries Using Spring Data GemFire](Spring-CQs.html)

This document describes how a Pivotal Cloud Foundry (PCF) app developer can choose a service plan, create and delete Pivotal Cloud Cache (PCC) service instances, and bind an app.

You must install the [Cloud Foundry Command Line Interface](http://docs.pivotal.io/pivotalcf/cf-cli/install-go-cli.html) (cf CLI) to run the commands in this topic.

## <a id="viewing"></a>Viewing All Plans Available for Pivotal Cloud Cache

Run `cf marketplace -s p-cloudcache` to view all plans available for PCC. The plan names displayed are configured by the operator on tile installation.

<pre class='terminal'>
$ cf marketplace -s p-cloudcache

Getting service plan information for service p-cloudcache as admin...
OK

service plan   description      free or paid
extra-small    Caching Plan 1   free
small          Caching Plan 2   free
medium         Caching Plan 3   free
large          Caching Plan 4   free
extra-large    Caching Plan 5   free
</pre>

## <a id="create"></a> Creating a Pivotal Cloud Cache Service Instance

Run `cf create-service p-cloudcache PLAN-NAME SERVICE-INSTANCE-NAME` to create a service instance. Replace `PLAN-NAME` with the name from the list of available plans. Replace `SERVICE-INSTANCE-NAME` with a name of your choice. Use this name to refer to your service instance with other commands. Service instance names can include alpha-numeric characters, hyphens, and underscores.

<pre class='terminal'>
$ cf create-service p-cloudcache extra-large my-cloudcache
</pre>

Service instances are created asynchronously. Run the `cf services` command to view the current status of the service creation, and of other service instances in the current org and space:

<pre class='terminal'>
$ cf services
Getting services in org my-org / space my-space as user...
OK

name            service        plan    bound apps   last operation
my-cloudcache   p-cloudcache   small                create in progress
</pre>

When completed, the status changes from `create in progress` to `create succeeded`.

### <a id="params"></a> Provide Optional Parameters

You can create a customized service instance by passing optional parameters to `cf create-service` using the `-c` flag. The `-c` flag accepts a valid JSON object containing service-specific configuration parameters, provided either in-line or in a file.

The PCC service broker supports the following parameters:

- `num_servers`: An integer that specifies the number of server instances in the cluster. The minimum value is `4`. The maximum and default values are configured by the operator.
- `new_size_percentage`: An integer that specifies the percentage of the heap to allocate to young generation. This value must be between `5` and `83`. By default, the new size is 2&nbsp;GB or 10% of heap, whichever is smaller.

The following example creates the service with five service instances in the cluster:

<pre class='terminal'>
$ cf create-service p-cloudcache small my-cloudcache -c '{"num_servers": 5}'
</pre>

### <a id="ssc"></a> Enable Session State Caching with the Java Buildpack

When the service instance name is followed by the `session-replication` tag, the Java buildpack downloads all the required resources for session state caching. This feature is available iin Java buildpack version 3.19 and higher, up to but not including version 4. It is then available again in version 4.3.

To enable session state caching, do one of the following:

+ When creating your service instance name, append it with the `session-replication` tag. For example, for the `p-cloudcache` service:

    <pre class='terminal'>
     $ cf create-service p-cloudcache my-service-instance -t session-replication</pre>

* When updating your service instance name (for example, if the updated name is `new-service-instance`), append it with the `session-replication` tag:

    <pre class='terminal'>
    $ cf update-service new-service-instance -t session-replication</pre>

* End the service instance name with the text `-session-replication`:
 `my-service-instance-session-replication`.

### <a id="ssc-spring-session"></a> Enable Session State Caching Using Spring Session

Session state caching for apps using [Spring Session](http://projects.spring.io/spring-session/) is a beta feature.
It uses pre-release versions of Spring Session libraries.

To use `spring-session` with PCC, follow the steps below:

1. Make the following changes to the app:
  * Replace existing Spring Session `@EnableXXXHttpSession` annotation with `@EnableGemFireHttpSession(maxInactiveIntervalInSeconds = N)` where `N` is seconds.
  * Add the `spring-session-data-geode` and `spring-data-geode` dependencies to the build.
  * Add beans to the Spring app config.

    For more information, see the [spring-session-data-gemfire-example](https://github.com/jxblum/spring-session-data-gemfire-example) repository.

2. Create a region named `ClusteredSpringSessions` in gfsh using the `cluster_operator_XXX` credentials:
  ```
  create region --name=ClusteredSpringSessions --type=PARTITION_HEAP_LRU
  ```

### <a id="service-instance-dev-plan"></a> Dev Plans

The Dev Plan is a type of service plan
that is useful for development and testing.
This example creates a Dev Plan service instance:

<pre class='terminal'>
$ cf create-service p-cloudcache dev-plan my-dev-cloudcache
</pre>

The plan provides a single locator and a single server colocated
within a single VM.
Because the VM is recycled when the service instance is updated or upgraded,
all data within the region is lost upon update or upgrade.

When post-deploy scripts are enabled for Ops Manager,
the service instance is created with a single sample region
called `example_partition_region`.
The region is of type `PARTITION_REDUNDANT_HEAP_LRU`,
as described in [Partitioned Region Types for Creating Regions on the Server](region-design.html#partitioned-types).

If `example_partition_region` has **not** been created,
it is probably because post-deploy scripts are not enabled for Ops Manager,
as described in [Configure a Dev Plan](./operator.html#dev-plan).

## <a id="WAN-create-setup"></a> Set Up WAN-Separated Service Instances

Two service instances may form a single distributed system across a WAN.
The interaction of the two service instances may follow one of 
the patterns described within the section on
[Design Patterns](design-patterns.html).

Call the two service instances A and B.
The GemFire cluster within each service instance uses an identifier
called a `distributed_system_id`.
This example assigns `distributed_system_id = 1` to Cluster A
and `distributed_system_id = 2` to Cluster B.
GemFire gateway senders provide the communication path and construct that
propagates region operations from one cluster to another.
On the receiving end are GemFire gateway receivers. 
Creating a service instance also creates gateway receivers.

### <a id="WAN-bidirectional-setup"></a> Set Up a Bidirectional System

This sequence of steps sets up a bidirectional transfer,
as will be needed for an active-active pattern, as described in
[Bidirectional Replication Across a WAN](design-patterns.html#active-active-WAN-pattern).

1. Create the cluster A service instance
using the cluster A Cloud Foundry administrative credentials.
This example explicitly sets the `distributed_system_id` of cluster A
using a `-c` option with a command of the form:

    ```
    cf create-service p-cloudcache PLAN-NAME SERVICE-INSTANCE-NAME -c '{
    "distributed_system_id" : ID-VALUE }'
    ```

    Here is a cluster A example of the `create-service` command:

    <pre class='terminal'>
    $ cf create-service p-cloudcache wan-cluster wan1 -c '{
    "distributed_system_id" : 1 }'
    </pre>

    Verify the completion of service creation prior to continuing
    to the next step.
    Output from the `cf services` command will show the `last operation` as
    `create succeeded` when service creation is completed.

1. Create a service key for cluster A.
The service key will contain generated credentials that this example
will use in the creation of the cluster B service instance:

    <pre class='terminal'>
    $ cf create-service-key wan1 k1
    </pre>

    Within the service key,
    each `username` is generated with a unique string
    appended so there will be unique user names for the different roles.
    The user names in this example have been modified
    to be easy to understand,
    and they are not representative of the user names that
    will be generated upon service key creation.
    Passwords generated for the service key are output in clear text.
    The passwords shown in this example have been
    modified to be easy to understand,
    and they are not representative of the passwords that
    will be generated upon service key creation.
    Here is sample output from `cf service-key wan1 k1`:

    <pre class='terminal'>
    Getting key k1 for service instance wan1 as admin...


    {
     "distributed_system_id": "1",
     "locators": [
      "10.0.16.21[55221]"
      "10.0.16.22[55221]"
      "10.0.16.23[55221]"
     ],
     "urls": {
      "gfsh": "http://cloudcache-1.example.com/gemfire/v1",
      "pulse": "http://cloudcache-1.example.com/pulse"
     },
     "users": [
      {
       "password": "cl-op-ABCDE-password",
       "roles": [
        "cluster_operator"
       ],
       "username": "cluster_operator_ABCDE"
      },
      {
       "password": "dev-FGHIJ-password",
       "roles": [
        "developer"
       ],
       "username": "developer_FGHIJ"
      }
     ],
     "wan": {
      "sender_credentials": {
       "active": {
        "password": "gws-KLMNO-password",
        "username": "gateway_sender_KLMNO"
       }
      }
     }
    }
    </pre>

1. Communicate the cluster A locators IP and port addresses and
`sender_credentials` to the cluster B Cloud Foundry administrator. 

1.  Create the cluster B service instance
using cluster B Cloud Foundry administrative credentials.
This example explicitly sets the `distributed_system_id`.
Use a `-c` option with the command to specify the `distributed_system_id`,
the cluster A service instance's locators,
and the cluster A `sender_credentials`:

    <pre class='terminal'>
    $ cf create-service p-cloudcache wan-cluster wan2 -c '
    {
      "distributed_system_id":2,
      "remote_clusters":[
      {
        "remote_locators":[
          "10.0.16.21[55221]",
          "10.0.16.22[55221]",
          "10.0.16.23[55221]"],
        "trusted_sender_credentials":[
        {
          "username": "gateway_sender_KLMNO",
          "password":"gws-KLMNO-password"
        }]
      }]
    }'
    </pre>

    Verify the completion of service creation prior to continuing
    to the next step.
    Output from the `cf services` command will show the `last operation` as
    `create succeeded` when service creation is completed.

1. Create the service key of cluster B:

    <pre class='terminal'>
    $ cf create-service-key wan2 k2
    </pre>

    Here is sample output from `cf service-key wan2 k2`,
    which outputs details of the cluster B service key:

    <pre class='terminal'>
    Getting key k2 for service instance destination as admin...

    {
     "distributed_system_id": "2",
     "locators": [
      "10.0.24.21[55221]"
      "10.0.24.22[55221]"
      "10.0.24.23[55221]"
     ],
     "urls": {
      "gfsh": "http://cloudcache-2.example.com/gemfire/v1",
      "pulse": "http://cloudcache-2.example.com/pulse"
     },
     "users": [
      {
       "password": "cl-op-PQRST-password",
       "roles": [
        "cluster_operator"
       ],
       "username": "cluster_operator_PQRST"
      },
      {
       "password": "dev-UVWXY-password",
       "roles": [
        "developer"
       ],
       "username": "developer_UVWXY"
      }
     ],
     "wan": {
      "remote_clusters": [
      {
        "remote_locators": [
          "10.0.16.21[55221]",
          "10.0.16.21[55221]",
          "10.0.16.21[55221]"
        ],
        "trusted_sender_credentials": [
         "gateway_sender_KLMNO"
        ]
       }
      ],
      "sender_credentials": {
       "active": {
        "password": "gws-ZABCD-password",
        "username": "gateway_sender_ZABCD"
       }
      }
     }
    }
    </pre>

1. Communicate the cluster B locators IP and port addresses and
`sender_credentials` to the cluster A Cloud Foundry administrator. 

1. Update the cluster A service instance using the cluster A
Cloud Foundry administrative credentials to include the cluster B locators
and the cluster B `sender_credentials`:

    <pre class='terminal'>
    $ cf update-service wan1 -c '
    {
      "remote_clusters":[
      {
        "remote_locators":[
          "10.0.24.21[55221]",
          "10.0.24.22[55221]",
          "10.0.24.23[55221]"],
        "trusted_sender_credentials":[
        {
          "username":"gateway_sender_ZABCD",
          "password":"gws-ZABCD-password"
        }]
      }]
    }'
    Updating service instance wan1 as admin
    </pre>

1. To observe and verify that the cluster A service instance has
been correctly updated,
it is necessary to delete and recreate the cluster A service key.
As designed, the recreated service key will have the same user identifiers
and passwords; new unique strings and passwords are not generated.
Use the cluster A Cloud Foundry administrative credentials
in these commands:

    <pre class='terminal'>
    $ cf delete-service-key wan1 k1
    </pre>

    <pre class='terminal'>
    $ cf create-service-key wan1 k1
    </pre>

    The cluster A service key will now appear as:

    <pre class='terminal'>
    Getting key k1 for service instance wan1 as admin...

    {
     "distributed_system_id": "1",
     "locators": [
      "10.0.16.21[55221]",
      "10.0.16.22[55221]",
      "10.0.16.23[55221]"
     ],
     "urls": {
      "gfsh": "http://cloudcache-1.example.com/gemfire/v1",
      "pulse": "http://cloudcache-1.example.com/pulse"
     },
     "users": [
      {
       "password": "cl-op-ABCDE-password",
       "roles": [
        "cluster_operator"
       ],
       "username": "cluster_operator_ABCDE"
      },
      {
       "password": "dev-FGHIJ-password",
       "roles": [
        "developer"
       ],
       "username": "developer_FGHIJ"
      }
     ],
     "wan": {
      "remote_clusters": [
       {
        "remote_locators": [
         "10.0.24.21[55221]",
         "10.0.24.22[55221]",
         "10.0.24.23[55221]"
        ],
        "trusted_sender_credentials": [
         "gateway_sender_ZABCD"
        ]
       }
      ],
      "sender_credentials": {
       "active": {
        "password": "gws-KLMNO-password",
        "username": "gateway_sender_KLMNO"
       }
      }
     }
    }
    </pre>


1. Use gfsh to create the cluster A gateway sender and the region.
Any region operations that occur after the region is created on
cluster A, but before the region is created on cluster B
will be lost.
    - Connect using gfsh and the cluster A `cluster_operator` credentials,
    which are needed to be authorized for the gateway sender
    creation operation:
        <pre class='terminal'>
        gfsh>connect --url=htt<span>p</span>://cloudcache-1.example.com/gemfire/v1 --use-http --user=cluster\_operator\_ABCDE --password=cl-op-ABCDE-password
        </pre>
    - Create the cluster A gateway sender.
    The required `remote-distributed-system-id` option identifies the `distributed-system-id` of the destination cluster. It is 2 for this example:

        <pre class='terminal'>
        gfsh>create gateway-sender --id=send_to_2 --remote-distributed-system-id=2 --enable-persistence=true
        </pre>
    - Create the cluster A region.
    The `gateway-sender-id` associates region operations with a specific
    gateway sender.  The region must have an associated gateway sender in
    order to propagate region events across the WAN.

        <pre class='terminal'>
        gfsh>create region --name=regionX --gateway-sender-id=send_to_2 --type=PARTITION_REDUNDANT
        </pre>

1. Use gfsh to create the cluster B gateway sender and region.
    - Connect using gfsh and the cluster B `cluster_operator` credentials,
    which are needed to be authorized for the gateway sender
    creation operation:
        <pre class='terminal'>
        gfsh>connect --url=htt<span>p</span>://cloudcache-2.example.com/gemfire/v1 --use-http --user=cluster\_operator\_PQRST --password=cl-op-PQRST-password
        </pre>
    - Create the cluster B gateway sender:

        <pre class='terminal'>
        gfsh>create gateway-sender --id=send_to_1 --remote-distributed-system-id=1 --enable-persistence=true
        </pre>
    - Create the cluster B region:

        <pre class='terminal'>
        gfsh>create region --name=regionX --gateway-sender-id=send_to_1 --type=PARTITION_REDUNDANT
        </pre>

## <a id="delete"></a> Deleting a Service Instance

You can delete service instances using the cf CLI. Before doing so, you must remove any existing service keys and app bindings.

1. Run `cf delete-service-key SERVICE-INSTANCE-NAME KEY-NAME` to delete the service key.
1. Run `cf unbind-service APP-NAME SERVICE-INSTANCE-NAME` to unbind your app from the service instance.
1. Run `cf delete-service SERVICE-INSTANCE-NAME` to delete the service instance.

<pre class='terminal'>
$ cf delete-service-key my-cloudcache my-service-key
$ cf unbind-service my-app my-cloudcache
$ cf delete-service my-cloudcache
</pre>

Deletions are asynchronous. Run `cf services` to view the current status of the service instance deletion.

## <a id="update-service-instance"></a> Updating a Pivotal Cloud Cache Service Instance

You can apply all optional parameters to an existing service instance using the `cf update-service` command. You can, for example, scale up a cluster by increasing the number of servers.

Previously specified optional parameters are persisted through subsequent updates. To return the service instance to default values, you must explicitly specify the defaults as optional parameters.

For example, if you create a service instance with five servers using a plan that has a default value of four servers:

<pre class='terminal'>
$ cf create-service p-cloudcache small my-cloudcache -c '{"num_servers": 5}'
</pre>

And you set the `new_size_percentage` to 50%:

<pre class='terminal'>
$ cf update-service my-cloudcache -c '{"new_size_percentage": 50}'
</pre>

Then the resulting service instance has `5` servers and `new_size_percentage` of 50% of heap.

### <a id="cluster-rebalancing"></a>Cluster Rebalancing

When updating a cluster to increase the number of servers, the available heap size is increased. When this happens, PCC automatically rebalances data in the cache to distribute data across the cluster.

This automatic rebalancing does not occur when a server leaves the cluster and later rejoins, for example when a VM is re-created, or network connectivity lost and restored.
 In this case, you must manually rebalance the cluster using the gfsh [`rebalance` command](http://gemfire.docs.pivotal.io/geode/tools_modules/gfsh/command-pages/rebalance.html) while authenticated as a cluster operator. 
<p class="note"><strong>Note</strong>: You must first [connect with gfsh](#gfsh-connect) before you can use the `rebalance` command.</p>

## <a id="plan-updates"></a> About Changes to the Service Plan

Your PCF operator can change details of the service plan available on the Marketplace. If your operator changes the default value of one of the optional parameters, this does not affect existing service instances.

However, if your operator changes the allowed values of one of the optional parameters, existing instances that exceed the new limits are not affected, but any subsequent service updates that change the optional parameter must adhere to the new limits.

For example, if the PCF operator changes the plan by decreasing the maximum value for `num_servers`, any future service updates must adhere to the new `num_servers` value limit.

You might see the following error message when attempting to update a service instance:

<pre class='terminal'>
$ cf update-service  my-cloudcache -c '{"num_servers": 5}'
Updating service instance my-cloudcache as admin...
FAILED
Server error, status code: 502, error code: 10001, message: Service broker error: Service cannot be updated at this time, please try again later or contact your operator for more information
</pre>

This error message indicates that the operator has made an update to the plan used by this service instance. You must wait for the operator to apply plan changes to all service instances before you can make further service instance updates.

