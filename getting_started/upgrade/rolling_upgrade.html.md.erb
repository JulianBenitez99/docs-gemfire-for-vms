---
title:  Rolling Upgrade
---

A rolling upgrade allows you to keep your existing distributed system 
running while individual system members are upgraded.

A rolling upgrade eliminates system downtime.
You upgrade one member at a time,
and each upgraded member can communicate with other members
that are still running the earlier version of GemFire.

## Supported Versions for Rolling Upgrade

A rolling upgrade can bring servers or peers running an 8.0, 8.1, or 8.2 version up to the most recent version of 8.2.

A rolling upgrade can also bring servers or peers running earlier versions of 9 up to the most recent version of 9.

Rolling upgrades apply to the peer members or cache servers within a distributed system.
Rolling upgrades may also be applied within a site of multi-site (WAN) deployments.
See [Version Compatibilities](upgrade_overview.html#version_compatibilities) 
for more details on how different versions of GemFire can interoperate.

Rolling upgrades can be performed only on systems in which all partitioned regions have full redundancy.
Check the redundancy state of all your regions *before* you begin the rolling upgrade and *before* stopping any members.
See [Checking Redundancy in Partitioned Regions](../../../geode/developing/partitioned_regions/checking_region_redundancy.html) for details.
If a rolling update is not possible for your system, follow the procedure in [Off-Line Upgrade](upgrade_with_downtime.html).

# Guidelines for Planning a Rolling Upgrade

-   Schedule your upgrade during a period of low user activity for your system and network.
-   **Important:** After all locators have been upgraded, *do not start or restart any processes* that are running the older version of the software. The older process will either not be allowed to join the distributed system; or if allowed to join, can potentially cause a deadlock.
-   When you perform a rolling upgrade, your online cluster will have a mix of members running different versions of GemFire.
During this time period, do not execute region operations such as region creation or region destruction.
Also, do not do a region rebalancing, unless `startup-recovery-delay` is set to -1 (disabled).
-   Do not modify region attributes or data either via `gfsh` or `cache.xml` configuration during the upgrade process.
-   Region rebalancing affects the restart process.
If you have `startup-recovery-delay=-1` configured (disabled) for your partitioned region, you will need to perform a rebalance on your
region after you restart each member. 
If rebalance occurs automatically, as it will if `startup-recovery-delay` is set to a value other than -1 (enabled), make sure that the rebalance completes between server restarts. 
If you have `startup-recovery-delay` enabled and set to a high number, you may need to wait extra time until the region has recovered redundancy, because rebalance must complete before new servers are restarted. 
The partitioned region attribute `startup-recovery-delay` is described in [Configure Member Join Redundancy Recovery for a Partitioned Region](/geode/developing/partitioned_regions/set_join_redundancy_recovery.html).


# Before Doing a Rolling Upgrade

-   Verify that all members that you wish to upgrade are members of the same distributed system cluster.
A list of cluster members will be output with the `gfsh` command:

    ``` pre
    gfsh>list members
    ```

-   Make a backup copy of your persistent data stores prior to upgrade.
The discussion at [Creating Backups for System Recovery and Operational Management](/geode/managing/disk_storage/backup_restore_disk_store.html#backup_restore_disk_store) explains the process,
and the [backup disk-store](/geode/tools_modules/gfsh/command-pages/backup.html) command reference page details using
the `gfsh backup disk-store` command to make a backup.

# Rolling Upgrade With Cluster Configuration - the Happy Path

1.  On the machine hosting the locator you wish to upgrade, install the new version of the software (alongside the older version of the software).
See [Installing Pivotal GemFire](../installation/install_intro.html).

2.  Open a terminal console on the host machine of the locator you are upgrading.

3.  Start a `gfsh` prompt, using the version from your current GemFire installation, and connect to the currently running locator.
    For example:

    ``` pre
    gfsh>connect --locator=locator_hostname_or_ip_address[port]
    ```

4.  Use `gfsh` commands to characterize your current installation so you can compare your post-upgrade system to the current one. 
For example, use the `list members` command to view locators and data members:

    ```
      Name   | Id
    -------- | ------------------------------------------------
    locator1 | 172.16.71.1(locator1:26510:locator)<ec><v0>:1024
    locator2 | 172.16.71.1(locator2:26511:locator)<ec><v1>:1025
    server1  | 172.16.71.1(server1:26514)<v2>:1026
    server2  | 172.16.71.1(server2:26518)<v3>:1027
    ```

5.  Stop a locator. For example:

    ``` pre
    gfsh>stop locator --name=locator1
    Stopping Locator running in /Users/username/sandbox/locator on 172.16.71.1[10334] as locator...
    Process ID: 96686
    Log File: /Users/username/sandbox/locator/locator.log
    ....
    No longer connected to 172.16.71.1[1099].
    ```
6. Start `gfsh` from the new GemFire installation.
    Verify that you are running the newer version with

    ``` pre
    gfsh>version
    ```

7. Start a locator using the same name as the older version you recently stopped. By using the same name and directory, the new locator can access the old locator's cluster configuration without having to import it in a separate step:

    ```
    gfsh>start locator --name=locator1 --enable-cluster-configuration=true --dir=/data/locator1
    ```

8. The new locator should reconnect to the same members as the older locator. Use `list members` to verify:

    ```
    gfsh>list members
      Name   | Id
    -------- | ----------------------------------------------------
    locator1 | 172.16.71.1(locator1:26752:locator)<ec><v17>:1024(version:UNKNOWN[ordinal=65])
    locator2 | 172.16.71.1(locator2:26511:locator)<ec><v1>:1025
    server1  | 172.16.71.1(server1:26514)<v2>:1026
    server2  | 172.16.71.1(server2:26518)<v3>:1027
    ```

    Interestingly, the system seems a bit confused about the software version for the new locator, locator1.

8. Upgrade the remaining locators by stopping and restarting them. When you have completed that step, the system gives a more coherent view of version numbers:

    ```
    gfsh>list members
      Name   | Id
    -------- | ----------------------------------------------------
    locator1 | 172.16.71.1(locator1:26752:locator)<ec><v17>:1024
    locator2 | 172.16.71.1(locator2:26808:locator)<ec><v30>:1025
    server1  | 172.16.71.1(server1:26514)<v2>:1026(version:GFE 9.0)
    server2  | 172.16.71.1(server2:26518)<v3>:1027(version:GFE 9.0)
    ```

    The server entries show that the servers are running an older (9.0) version of gemfire: `(version:GFE 9.0)`.

9. Upgrade each server, one at a time, by stopping it and restarting it. Restart the server with the same command-line options with which it was originally started in the previous installation. For example:

    ```
    gfsh>stop server --name=server1
    Stopping Cache Server running in /Users/share/server1 on 172.16.71.1[52139] as server1...

    gfsh>start server --name=server1 --use-cluster-configuration=true --server-port=0 --dir=/data/server1
    Starting a Geode Server in /Users/share/server1...
    ```

    Use the `list members` command to verify that the server is now running the new version of GemFire:

    ```
    gfsh>list members
      Name   | Id
    -------- | ----------------------------------------------------
    locator1 | 172.16.71.1(locator1:26752:locator)<ec><v17>:1024
    locator2 | 172.16.71.1(locator2:26808:locator)<ec><v30>:1025
    server1  | 172.16.71.1(server1:26835)<v32>:1026
    server2  | 172.16.71.1(server2:26518)<v3>:1027(version:GFE 9.0)
    ```

10. Repeat until all servers are running the new version of GemFire.


### After Upgrading the Servers

**As desired, upgrade GemFire clients.** 

You can only do this after you have completed the upgrade on all locator and server members in the
cluster.  See [Upgrading Clients](upgrade_clients.html) for details.

##  Checking Member Versions in a Mixed Cluster

During a rolling upgrade, you can check the current GemFire version of all members in the cluster by looking at the server or locator logs.

When an upgraded member reconnects to the distributed system, it logs all the members it can see as well as the GemFire version of those members. For example, an upgraded locator will now detect GemFire members running the older version of GemFire (in this case, the version being upgraded-- GFE 8.0.0) :

``` pre
[info 2013/06/03 10:03:29.206 PDT frodo <vm_1_thr_1_frodo> tid=0x1a]  DistributionManager frodo(locator1:21869:locator)<v16>:28242 started on frodo[15001]. There
        were 2 other DMs. others: [frodo(server2:21617)<v4>:14973( version:GFE 8.0.0 ), frodo(server1:21069)<v1>:60929( version:GFE 8.0.0 )] (locator)
```

After some members have been upgraded, non-upgraded members will log the following message when they receive a new membership view:

``` pre
Membership: received new view [frodo(locator1:20786)<v0>:32240|4]
          [frodo(locator1:20786)<v0>:32240/51878, frodo(server1:21069)<v1>:60929/46949,
          frodo(server2:21617)<v4>( version:UNKNOWN[ordinal=23] ):14973/33919]
```

Non-upgraded members identify members that have been upgraded to the next version with `version: UNKNOWN`.


